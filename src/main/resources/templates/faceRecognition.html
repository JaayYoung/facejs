<!DOCTYPE html>
<html lang="en" xmlns:th="http://www.thymeleaf.org">
<head>
    <base th:href="${#request.getContextPath()}+'/'">
    <meta charset="UTF-8">
    <title>人脸考勤</title>
    <script src="face-api.js"></script>
    <script src="/js/commons.js"></script>
    <link rel="stylesheet" href="/css/materialize.css">
    <link rel="stylesheet" href="styles.css">
    <script type="text/javascript" src="/js/jquery-2.1.1.min.js"></script>
    <script src="/js/materialize.min.js"></script>
</head>
<body>

<div>

    <video id="video" autoplay muted loop playsinline></video>
    <canvas id="overlay"></canvas>


</div>
</body>

<script th:inline="javascript" type="text/javascript">

    // const displaySize = {width: 200, height: 200};
    let canvas = document.getElementById('overlay');
    let video = document.getElementById('video');
    let facedescriptor = new Float32Array(128);
    //getUserMedia 返回摄像头的流数据
    if (navigator.mediaDevices.getUserMedia === undefined) {
        navigator.mediaDevices.getUserMedia = function (options) {   // 首先，如果有getUserMedia的话，就获得它
            let userMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;

            // 一些浏览器根本没实现它 - 那么就返回一个error到promise的reject来保持一个统一的接口
            if (!userMedia) {
                return Promise.reject(new Error('userMedia is not implemented in this browser'));
            }

            // 否则，为老的navigator.getUserMedia方法包裹一个Promise
            return new Promise(function (resolve, reject) {
                userMedia.call(navigator, options, resolve, reject);
            });
        }
    }

    //参数
    const options = {
        video: true,
        audio: false
    };
    let promise = navigator.mediaDevices.getUserMedia(options);
    //打开设备，获取数据流
    promise.then(stream => {
        // 旧的浏览器可能没有srcObject
        if ("srcObject" in video) {
            video.srcObject = stream;
        } else {
            // 防止再新的浏览器里使用它，应为它已经不再支持了
            video.src = window.URL.createObjectURL(stream);
        }
        //如果数据已经加载了，就播放
        video.onloadedmetadata = (e) => {
            video.play();
        };
    }).catch(err => {
        console.error(err.name + ": " + err.message);
    });

    //监听摄像头播放事件
    video.addEventListener('play', () => {

        facemarker()
        setInterval(facemarker, 1500);   //第秒种输出一次结果

    });


    async function facemarker() {
        if (!faceapiIsReady()) {
            return;
        }
        const options = new faceapi.TinyFaceDetectorOptions({scoreThreshold: 0.2, inputSize: 608});
        const detections = await faceapi.detectAllFaces(video, options).withFaceLandmarks().withFaceDescriptors();     //
        if (!detections || detections.length <= 0) {
            return;
        }
        let attid = 1;
        var arr = [[${fea}]];
        var actid = [[${actid}]];
        // console.log(arr);
        for (let i = 0; i < 128; i++) {
            facedescriptor[i] = parseFloat(arr[i]);
        }

        // console.log(facedescriptor);
        //先加载维护好的人脸数据(人脸的特征数据和标签，用于后面的比对)
        // const labeledFaceDescriptors = await loadLabeledImages()
        const faceMatcher = new faceapi.FaceMatcher(facedescriptor, 0.6);
        const dims = faceapi.matchDimensions(canvas, video, true);
        const resizedDetections = faceapi.resizeResults(detections, dims);
        const results = resizedDetections.map(d => faceMatcher.findBestMatch(d.descriptor))
        results.forEach((result, i) => {
            //显示比对的结果
            const box = resizedDetections[i].detection.box
            const drawBox = new faceapi.draw.DrawBox(box, {label: result.toString()})
            drawBox.draw(canvas)
            console.log(result)
            if (result.distance < 0.6) {

                $.post('/attendrecord/addrecord', {"attid": attid, "actid": actid}, function (flag) {
                    if (flag) {
                        alert("考勤成功");
                    } else {
                        alert("请不要重复考勤！");
                    }

                })
            }
        })
    }

    function getCurrentFaceDetectionNet() {
        return faceapi.nets.tinyFaceDetector;
    }

    /**
     * 人脸api是否准备好
     * @author
     * @date 2020/8/8 18:16
     */
    function faceapiIsReady() {
        return !!getCurrentFaceDetectionNet().params
    }

    //人脸识别初始化配置
    async function init() {
        await getCurrentFaceDetectionNet().load('/weights');        //神经网络加载
        await faceapi.loadFaceLandmarkModel('/weights');            //人脸识别必须
        await faceapi.loadFaceRecognitionModel('/weights');        //人脸识别必须
    }

    // //读取人脸标签数据
    // async function loadLabeledImages() {
    //   //获取人脸图片数据,包含：图片+标签
    //   const data = await $.get('/FaceLibs/杨家良.jpg');
    //   //对图片按标签进行分类
    //   const labels = [...new Set(data.map(item => item.Label))]
    //   console.log(labels);
    //   return Promise.all(
    //           labels.map(async label => {
    //             const descriptions = []
    //             const imgs = data.filter(item => item.Label == label);
    //             for (let i = 0; i < imgs.length; i++) {
    //               const item = imgs[i];
    //               const img = await faceapi.fetchImage(`${item.ImgUrl}`)
    //               //console.log(item.ImgUrl, img);
    //               //const detections = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor()
    //               //识别人脸的初始化参数
    //               const options = new faceapi.SsdMobilenetv1Options({minConfidence: 0.38})
    //               //const options = new faceapi.TinyFaceDetectorOptions()
    //               //const options = new faceapi.MtcnnOptions()
    //               //扫描图片中人脸的轮廓数据
    //               const detections = await faceapi.detectSingleFace(img, options).withFaceLandmarks().withFaceDescriptor()
    //               console.log(detections);
    //               if (detections) {
    //                 descriptions.push(detections.descriptor)
    //               } else {
    //                 console.warn('Unrecognizable face')
    //               }
    //             }
    //             console.log(label, descriptions);
    //             return new faceapi.LabeledFaceDescriptors(label, descriptions)
    //           })
    //   )
    // }

    $(() => {
        init();
    })

</script>

</html>